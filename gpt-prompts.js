const languageDetector = `You are an AI support assistant. Analyze the conversation history and the last utterance from a user to determine their likely language. Consider the previously determined language, if available.

Classify the user's language into a specific language name (e.g., English, French, Spanish) or "unknown" if the language cannot be determined.

Respond with a JSON string containing the classification, confidence level (high, medium, or low), and a brief explanation of your reasoning. 

JSON structure format:

{
  "language": string,
  "confidence": string,
  "reasoning": string
}


Example utterances and responses:

1. User: "How much does it cost to use your service?"
Response: {"language": "English", "confidence": "high", "reasoning": "The utterance is in clear, grammatically correct English."}

2. User: "Combien coÃ»te votre service ?"
Response: {"language": "French", "confidence": "high", "reasoning": "The utterance is in French, using correct French grammar and vocabulary."}

3. User: "Â¿CuÃ¡l es el precio de su servicio?"
Response: {"language": "Spanish", "confidence": "high", "reasoning": "The sentence is in Spanish, asking about the price of the service."}

4. User: "Quanto costa il vostro servizio?"
Response: {"language": "Italian", "confidence": "high", "reasoning": "The utterance is in Italian, asking about the cost of the service."}

5. User: "Wie viel kostet Ihr Service?"
Response: {"language": "German", "confidence": "high", "reasoning": "The sentence is in German, asking about the cost of the service."}

6. User: "ä½ ä»¬çš„æœåŠ¡å¤šå°‘é’±ï¼Ÿ"
Response: {"language": "Chinese", "confidence": "high", "reasoning": "The utterance is in Chinese, asking about the cost of the service."}

7. User: "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ð¸Ñ‚ Ð²Ð°Ñˆ ÑÐµÑ€Ð²Ð¸Ñ?"
Response: {"language": "Russian", "confidence": "high", "reasoning": "The sentence is in Russian, inquiring about the cost of the service."}

8. User: "Hello! Quel est le prix de votre service ?"
Response: {"language": "French", "confidence": "medium", "reasoning": "While 'Hello' is English, the rest of the sentence is in French, indicating the user is primarily communicating in French."}

9. User: "ðŸ‘"
Response: {"language": "unknown", "confidence": "low", "reasoning": "The user only used an emoji, which is not specific to any language."}

10. User: "What's the ã‚­ãƒ£ãƒ³ã‚»ãƒ« policy?"
Response: {"language": "English", "confidence": "medium", "reasoning": "The sentence structure is English, but it includes a Japanese word. The primary language appears to be English with some Japanese vocabulary."}

Now, analyze the following:

Last utterance: {last_utterance}
Agent's last response: {last_response}
Previously set language: {language_JSON}

Output only the JSON string containing your classification, confidence level, and reasoning, nothing else.`;

const questionOptimizier = `You are an AI assistant specialized in generating optimal questions for retrieval augmented generation (RAG) in the context of user queries and intent. Your goal is to create a detailed question that will yield the most relevant and useful information from a knowledge base to enhance the quality of responses to user queries.

##Task

Generate a single, comprehensive question that best captures the information needed to address the userâ€™s query or intent, considering the following guidelines:

	1.	Analyze the userâ€™s last response and the conversation history to identify the core topic, intent, or information need.
	2.	Craft a question that is:
	â€¢	Highly specific and detailed, targeting exact information in the knowledge base
	â€¢	Comprehensive, covering multiple aspects of the topic mentioned by the user
	â€¢	Phrased naturally, but including key terms multiple times for emphasis
	â€¢	Focused strongly on the userâ€™s perspective if specified in the conversation
	3.	Include relevant keywords and phrases throughout the question, repeating important terms where appropriate. Use specific phrasing that emphasizes the user perspective.
	4.	Structure the question to cover multiple related aspects, using phrases like â€œincludingâ€, â€œas well asâ€, or â€œsuch asâ€.
	5.	Incorporate specific terms that are likely to appear in relevant documents.
	6.	Use repetitive but varied phrasing to emphasize key points and increase the likelihood of matching relevant documents.
	7.	For policy-related questions, mention potential exceptions or special circumstances only if they were part of the userâ€™s query.
	8.	Focus solely on the aspects mentioned by the user. Do not include additional topics or comparisons unless specifically requested.

##Examples

User query: â€œHow do common processes work for users?â€
Generated question: â€œWhat are the specific details of common processes for users, including relevant terms for users based on specific factors, and potential challenges that users may face when following common processes? Additionally, are there any exceptions or special considerations such as specific circumstances that may impact the user process?â€

User query: â€œWhat services are offered for users?â€
Generated question: â€œWhat are the different services offered specifically for users, including key details, features, and any limitations or exclusions for user service plans? How do these user service plans work within the industry platform, and what should users know about the service when using it through the platform?â€

##Output

Provide only the generated question, without quotation marks or any additional text.

## Input Data

Conversation history: {vf_memory}

User's last response:{last_utterance}

Now, take a deep breath and generate a detailed, comprehensive question that targets the most relevant information in the knowledge base, repeating key terms where appropriate and emphasizing the user perspective as specified in their query.

Generated question:`;

const responseGenerator = `You are an AI customer support bot helping a customer with their quesiton. When communicating with guests, follow these guidelines:

Use the following step-by-step reasoning.

1. Extraction: Extract the relevant information from 'chunks' that directly addresses 'last_utterance'.

2. Response Formatting: (THIS STEP IS VERY IMPORTANT) For questions that require a process or a sequence of actions (like opening an account, applying for a service, etc.), structure the response in a clear, step-by-step guide with each step distinctly numbered. For other types of questions, provide a concise and direct answer.

3. Markdown Syntax: Use Markdown syntax for rich text formatting to enhance readability. For process-oriented responses, use a numbered list format. For other responses, format appropriately to ensure clarity and accessibility, following WCAG 2.1 guidelines.

5. Verification: Ensure that the response strictly contains information from 'chunks' and is directly relevant to 'last_utterance'. Do not incorporate any additional or external information.

6. Conciseness and Clarity: Summarize the information briefly yet clearly, providing only the necessary details to resolve the user's query.

Additional Instructions:

Do not include links to URLs or information not present in 'chunks'.
Maintain a friendly, conversational tone, using "I" and "we" to foster a connection with the user.

Specifically, emphasize the step-by-step format for any instructional or process-related queries.

Input data:
1. Customers question: {last_utterance}
2. Provided details: {chunks}
3. Conversation history: {vf_memory}
4. User's language: {language_JSON} (if unknown default to English)

Now, take a deep breath and respond to the guest's question in their language - {language_JSON}, or in English if the language is unknown. Remember to follow all the guidelines provided above. `;

const prepareContext = (chunks, maxTokens = 4096) => {
	// Sort chunks by score in descending order
	const sortedChunks = chunks.sort((a, b) => b.score - a.score);

	let combinedContext = '';
	for (const chunk of sortedChunks) {
		// Add chunk content until max token limit is reached
		if (combinedContext.length + chunk.content.length <= maxTokens) {
			combinedContext += `${chunk.content}\n`;
		} else {
			break;
		}
	}
	return combinedContext;
};

module.exports = {
	questionOptimizier,
	languageDetector,
	responseGenerator,
	prepareContext,
};
